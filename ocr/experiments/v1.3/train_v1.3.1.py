import os
import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import wandb
import random
import numpy as np
from torch.utils.data import DataLoader, WeightedRandomSampler
from collections import Counter
from torchvision import transforms
from utils.dataset import OCRDataset
from utils.dataset import OCRLabelOnlyDataset
from utils.label_encoder import LabelEncoder
from model.crnn import CRNN

# ë¬¸ì ë‹¨ìœ„ ì •í™•ë„
def char_accuracy(gt, pred):
    match = sum(g == p for g, p in zip(gt, pred))
    return match / max(len(gt), len(pred)) * 100

# Beam Search ë””ì½”ë”© (simple version)
def decode_beam_search(logits, encoder, beam_width=3):
    log_probs = logits.log_softmax(2).cpu().detach().numpy()  # [W, B, C]
    log_probs = np.transpose(log_probs, (1, 0, 2))  # [B, W, C]

    results = []
    for seq in log_probs:
        paths = [([], 0)]  # (sequence, score)
        for t in seq:
            new_paths = []
            topk = np.argsort(t)[-beam_width:][::-1]  # top-k indices
            for path, score in paths:
                for k in topk:
                    new_path = path + [k]
                    new_score = score + t[k]
                    new_paths.append((new_path, new_score))
            paths = sorted(new_paths, key=lambda x: x[1], reverse=True)[:beam_width]
        best_path = paths[0][0]
        decoded = encoder.decode_ctc_standard(best_path)
        results.append(decoded)
    return results


# í‰ê°€ í•¨ìˆ˜ - Beam Search ê¸°ë°˜
def evaluate(model, val_loader, encoder):
    model.eval()
    total = 0
    correct = 0
    with torch.no_grad():
        for images, texts in val_loader:
            images = images.to(device)
            outputs = model(images)
            pred_text = decode_beam_search(outputs, encoder, beam_width=5)[0]
            gt_text = texts[0]
            total += 1
            if pred_text == gt_text:
                correct += 1
    acc = correct / total * 100
    return acc

def create_prefix_sampler(dataset, prefix_len=3):
    label_list = [dataset[i] for i in range(len(dataset))]
    prefix_list = [label[:prefix_len] for label in label_list]
    freq = Counter(prefix_list)
    weights = [1.0 / freq[label[:prefix_len]] for label in label_list]
    sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)
    return sampler

if __name__ == "__main__":
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    wandb.init(
        project="crnn-ocr",
        name="train_v1.3.1",
        dir="wandb_logs",
        config={
            "batch_size": 32,
            "lr": 0.0005,
            "epochs": 100,
            "hidden_size": 512,
            "decoder": "ctc_standard"
        }
    )
    config = wandb.config

    transform = transforms.Compose([
        transforms.Resize((32, 128)),
        transforms.RandomAffine(degrees=1, translate=(0.01, 0.01)),
        ## í•™ìŠµì‹œ '37ë°”'ì— ë¬¶ì—¬ë²„ë¦¬ëŠ” í˜„ìƒì˜ ì›ì¸ìœ¼ë¡œ íŒŒì•…ë¨
        #transforms.ColorJitter(brightness=0.2, contrast=0.2),
        #transforms.RandomPerspective(distortion_scale=0.2, p=0.5),
        #transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0)),
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])

    train_dataset = OCRDataset(
        image_dir='data/images/train',
        label_dir='data/labels/train',
        transform=transform,
    )

    val_dataset = OCRDataset(
        image_dir='data/images/val',
        label_dir='data/labels/val',
        transform=transform,
    )

    # label only dataset (no transform)
    label_dataset = OCRLabelOnlyDataset(
        label_dir='data/labels/train',
    )
    
    # WeightedSampler ì ìš©
    sampler = create_prefix_sampler(label_dataset, prefix_len=3)

    train_loader = DataLoader(
        train_dataset,
        batch_size=config.batch_size,
        sampler=sampler,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )
    val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=2)

    encoder = LabelEncoder()
    num_classes = encoder.num_classes()

    model = CRNN(num_classes=num_classes, hidden_size=config.hidden_size).to(device)
    criterion = nn.CTCLoss(blank=0, zero_infinity=True)
    optimizer = optim.Adam(model.parameters(), lr=config.lr)

    # âœ… OneCycleLR ìŠ¤ì¼€ì¤„ëŸ¬ ì ìš©
    scheduler = torch.optim.lr_scheduler.OneCycleLR(
        optimizer,
        max_lr=config.lr,
        steps_per_epoch=len(train_loader),
        epochs=config.epochs,
        pct_start=0.1,
        anneal_strategy='cos',
        div_factor=25.0
    )

    best_acc = 0.0
    log = []
    patience = 20  # ì„±ëŠ¥ì´ ê°œì„ ë˜ì§€ ì•Šì•„ë„ ê¸°ë‹¤ë¦´ ìµœëŒ€ epoch ìˆ˜
    counter = 0    # í˜„ì¬ patience ì¹´ìš´í„°

    try:
        for epoch in range(config.epochs):
            model.train()
            running_loss = 0.0
            for batch_idx, (images, texts) in enumerate(train_loader):
                images = images.to(device)

                targets = [torch.tensor(encoder.encode(t), dtype=torch.long) for t in texts]
                target_lengths = torch.tensor([len(t) for t in targets], dtype=torch.long)
                targets_concat = torch.cat(targets).to(device)

                batch_size = images.size(0)
                output = model(images)
                input_lengths = torch.full(size=(batch_size,), fill_value=output.size(0), dtype=torch.long).to(device)

                loss = criterion(output.log_softmax(2), targets_concat, input_lengths, target_lengths)
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                scheduler.step()  # ğŸ”¥ OneCycleLRëŠ” ë°°ì¹˜ ë‹¨ìœ„ë¡œ step()

                running_loss += loss.item()

            if not os.path.exists('checkpoints'):
                os.makedirs('checkpoints')

            val_acc = evaluate(model, val_loader, encoder)
            print(f"[Epoch {epoch+1}] Loss: {running_loss / len(train_loader):.4f} | Val Acc: {val_acc:.4f}%")

            torch.save(model.state_dict(), f'checkpoints/crnn_epoch_{epoch+1}.pth')
            print(f"âœ… ëª¨ë¸ ì €ì¥ë¨: checkpoints/crnn_epoch_{epoch+1}.pth")

            if val_acc > best_acc:
                best_acc = val_acc
                counter = 0  # ê°œì„ ë˜ì—ˆìœ¼ë¯€ë¡œ ë¦¬ì…‹
                torch.save(model.state_dict(), 'checkpoints/best_model.pth')
                print(f"ğŸŒŸ í–¥ìƒ ëª¨ë¸ ê°±ì‹ ë¨! ì €ì¥ë¨: checkpoints/best_model.pth")
            else:
                counter += 1
                print(f"â³ í–¥ìƒë˜ì§€ ì•ŠìŒ (counter: {counter}/{patience})")
                if counter >= patience:
                    print("â›”ï¸ Early stopping triggered!")
                    break

            # ì˜ˆì‹œ ë””ì½”ë”© ì¶œë ¥ (ë¬´ì‘ìœ„ ìƒ˜í”Œ 3ê°œ ì¶œë ¥)
            model.eval()
            with torch.no_grad():
                sample_indices = random.sample(range(len(train_dataset)), 3)
                for idx in sample_indices:
                    sample_img, sample_text = train_dataset[idx]
                    sample_img = sample_img.unsqueeze(0).to(device)
                    pred = model(sample_img)
                    pred_std = encoder.decode_ctc_standard(pred.softmax(2).argmax(2)[:, 0].cpu().numpy())
                    pred_beam = decode_beam_search(pred, encoder, beam_width=5)[0]
                    acc = char_accuracy(sample_text, pred_std)
                    print(f"[ìƒ˜í”Œ] GT: {sample_text}")
                    print(f"  â”” Pred (í‘œì¤€ CTC): {pred_std} | Char Acc: {acc:.4f}%")
                    print(f"  â”” Pred (Beam Search): {pred_beam}")

            avg_loss = running_loss / len(train_loader)
            wandb.log({
                "epoch": epoch + 1,
                "loss": avg_loss,
                "val_acc": val_acc,
                "char_accuracy": acc,
                "lr": optimizer.param_groups[0]["lr"]
            })
            log.append((epoch + 1, avg_loss, val_acc))

    except KeyboardInterrupt:
        print("\nâ›”ï¸ í•™ìŠµ ì¤‘ë‹¨ë¨! ë§ˆì§€ë§‰ ìƒíƒœ ì €ì¥ ì¤‘...")
        torch.save(model.state_dict(), 'checkpoints/last_interrupted.pth')
        print("ğŸ“‚ ë§ˆì§€ë§‰ ìƒíƒœ ì €ì¥ë¨: checkpoints/last_interrupted.pth")

    wandb.finish()

    df = pd.DataFrame(log, columns=['epoch', 'loss', 'val_acc'])
    df.to_csv('train_log.csv', index=False)
    print("ğŸ“„ í•™ìŠµ ë¡œê·¸ ì €ì¥ë¨: train_log.csv")
